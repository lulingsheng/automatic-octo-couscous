# -*- coding: utf-8 -*-
"""
AI å¤§æ¨¡å‹æ™ºèƒ½åˆ†æå¼•æ“ - è±†åŒ…ç‰ˆæœ¬ (Volcengine Doubao)
æ¥å…¥ç«å±±å¼•æ“è±†åŒ…å¤§æ¨¡å‹ï¼Œå®ç°çœŸå®çš„ AI å¯¹è¯å’Œå›¾è¡¨ç”Ÿæˆ
ä½¿ç”¨ OpenAI SDK å…¼å®¹æ¥å£
"""

import json
import re
from datetime import datetime
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go


class DoubaoAgent:
    """è±†åŒ… AI æ™ºèƒ½åˆ†æå¼•æ“ï¼ˆåŸºäº OpenAI SDKï¼‰"""
    
    def __init__(self, api_key=None, endpoint_id=None, model_name=None, use_mock=False):
        """
        åˆå§‹åŒ–è±†åŒ… AI å¼•æ“
        
        Args:
            api_key: ç«å±±å¼•æ“ ARK API Key (å¿…å¡«)
            endpoint_id: è±†åŒ…æ¨ç†æ¥å…¥ç‚¹ ID (å¿…å¡«ï¼Œæ ¼å¼: ep-20260117181412-r9r6m)
            model_name: æ¨¡å‹åç§° (é»˜è®¤: deepseekapiv3.2)
            use_mock: æ˜¯å¦ä½¿ç”¨ Mock æ¨¡å¼ (é»˜è®¤ False)
        """
        self.api_key = api_key or "117aeeb4-df58-4e55-bebd-1e5aeab6a1e4"  # ğŸ”‘ æ‚¨çš„ API Key
        self.endpoint_id = endpoint_id or "ep-20260117181412-r9r6m"  # ğŸ”‘ æ‚¨çš„ Endpoint ID
        self.model_name = model_name or "deepseekapiv3.2"  # ğŸ”‘ æ¨¡å‹åç§°
        self.use_mock = use_mock
        
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        if not use_mock:
            try:
                from openai import OpenAI
                
                self.client = OpenAI(
                    base_url='https://ark.cn-beijing.volces.com/api/v3',
                    api_key=self.api_key
                )
                print("âœ“ è±†åŒ… AI å¼•æ“å·²å¯åŠ¨: çœŸå® API æ¨¡å¼ (OpenAI SDK)")
                print(f"âœ“ Model: {self.model_name}")
                print(f"âœ“ Endpoint ID: {self.endpoint_id}")
            except ImportError:
                print("âš ï¸ openai åº“æœªå®‰è£…ï¼Œé™çº§ä½¿ç”¨ Mock æ¨¡å¼")
                print("   å®‰è£…å‘½ä»¤: pip install --upgrade 'openai>=1.0'")
                self.use_mock = True
            except Exception as e:
                print(f"âš ï¸ è±†åŒ… API åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                print("   é™çº§ä½¿ç”¨ Mock æ¨¡å¼")
                self.use_mock = True
        
        if self.use_mock:
            print("âœ“ AI å¼•æ“å·²å¯åŠ¨: Mock æ¨¡æ‹Ÿæ¨¡å¼")
    
    def chat(self, query, dataframe_context=None, stream=False):
        """
        æ™ºèƒ½å¯¹è¯æ¥å£ (æ”¯æŒæ•°æ®ä¸Šä¸‹æ–‡å’Œå›¾è¡¨ç”Ÿæˆ)
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            dataframe_context: DataFrame ä¸Šä¸‹æ–‡ (å¯é€‰)
            stream: æ˜¯å¦æµå¼è¾“å‡º (é»˜è®¤ False)
            
        Returns:
            dict: {
                'answer': str,           # æ–‡æœ¬å›ç­”
                'show_chart': bool,      # æ˜¯å¦æ˜¾ç¤ºå›¾è¡¨
                'chart_type': str,       # å›¾è¡¨ç±»å‹ ('bar'|'line'|'pie'|'scatter'|null)
                'chart_col': str,        # æ•°æ®åˆ—å
                'raw_response': str      # åŸå§‹å“åº”
            }
            æˆ– generator (å½“ stream=True æ—¶)
        """
        if self.use_mock:
            return self._mock_chat(query, dataframe_context)
        else:
            # ç¡®ä¿ stream å‚æ•°æ­£ç¡®ä¼ é€’
            result = self._real_chat(query, dataframe_context, stream=stream)
            return result
    
    def _build_system_prompt(self, dataframe_context=None):
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        base_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èæ•°æ®åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿æ•°æ®åˆ†æå’Œå¯è§†åŒ–ã€‚

ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. ç†è§£ç”¨æˆ·çš„é—®é¢˜
2. æä¾›ä¸“ä¸šçš„åˆ†æå›ç­”
3. åˆ¤æ–­æ˜¯å¦éœ€è¦ç”Ÿæˆå›¾è¡¨æ¥è¾…åŠ©è¯´æ˜

**é‡è¦è§„åˆ™**ï¼š
- ä½ å¿…é¡»ä»¥ JSON æ ¼å¼è¿”å›ç»“æœ
- JSON æ ¼å¼å¦‚ä¸‹ï¼š
```json
{
    "answer": "ä½ çš„æ–‡æœ¬å›ç­”",
    "show_chart": true/false,
    "chart_type": "bar/line/pie/scatter/null",
    "chart_col": "æ•°æ®åˆ—åæˆ–null"
}
```

**å›¾è¡¨ç”Ÿæˆè§„åˆ™**ï¼š
- å½“ç”¨æˆ·è¦æ±‚"ç”»å›¾"ã€"å¯è§†åŒ–"ã€"å±•ç¤ºå›¾è¡¨"ã€"åˆ†æè¶‹åŠ¿"æ—¶ï¼Œè®¾ç½® show_chart=true
- æ ¹æ®æ•°æ®ç±»å‹é€‰æ‹©åˆé€‚çš„å›¾è¡¨ç±»å‹ï¼š
  - bar: æŸ±çŠ¶å›¾ï¼Œé€‚åˆæ¯”è¾ƒä¸åŒç±»åˆ«
  - line: æŠ˜çº¿å›¾ï¼Œé€‚åˆå±•ç¤ºè¶‹åŠ¿
  - pie: é¥¼å›¾ï¼Œé€‚åˆå±•ç¤ºå æ¯”
  - scatter: æ•£ç‚¹å›¾ï¼Œé€‚åˆå±•ç¤ºç›¸å…³æ€§
- chart_col åº”è¯¥æ˜¯æ•°æ®ä¸­å­˜åœ¨çš„åˆ—å
"""
        
        if dataframe_context is not None:
            columns = dataframe_context.columns.tolist()
            sample_data = dataframe_context.head(3).to_dict('records')
            
            context_info = f"""

**å½“å‰æ•°æ®ä¸Šä¸‹æ–‡**ï¼š
- æ•°æ®åˆ—: {', '.join(columns)}
- æ•°æ®æ ·ä¾‹: {json.dumps(sample_data, ensure_ascii=False, indent=2)}
- æ•°æ®è¡Œæ•°: {len(dataframe_context)}

è¯·åŸºäºè¿™äº›æ•°æ®å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
"""
            base_prompt += context_info
        
        return base_prompt
    
    def _real_chat(self, query, dataframe_context=None, stream=False):
        """çœŸå® API è°ƒç”¨ï¼ˆä½¿ç”¨ OpenAI SDK å…¼å®¹æ¥å£ï¼‰"""
        if stream:
            return self._real_chat_stream(query, dataframe_context)
        else:
            return self._real_chat_normal(query, dataframe_context)
    
    def _real_chat_normal(self, query, dataframe_context=None):
        """éæµå¼ API è°ƒç”¨"""
        try:
            # æ„å»ºæ¶ˆæ¯
            system_prompt = self._build_system_prompt(dataframe_context)
            
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": query}
            ]
            
            # è°ƒç”¨ API
            response = self.client.chat.completions.create(
                model=self.endpoint_id,  # ä½¿ç”¨ endpoint_id ä½œä¸º model
                messages=messages,
                temperature=0.7,
                max_tokens=2000
            )
            
            response_text = response.choices[0].message.content
            
            # è§£æå“åº”
            result = self._parse_response(response_text)
            return result
        
        except Exception as e:
            print(f"è±†åŒ… API è°ƒç”¨å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                'answer': f"æŠ±æ­‰ï¼ŒAI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚é”™è¯¯ä¿¡æ¯: {str(e)}",
                'show_chart': False,
                'chart_type': None,
                'chart_col': None,
                'raw_response': ''
            }
    
    def _real_chat_stream(self, query, dataframe_context=None):
        """æµå¼ API è°ƒç”¨"""
        try:
            # æ„å»ºæ¶ˆæ¯
            system_prompt = self._build_system_prompt(dataframe_context)
            
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": query}
            ]
            
            # è°ƒç”¨ API - æµå¼è¾“å‡º
            response_text = ""
            stream_response = self.client.chat.completions.create(
                model=self.endpoint_id,  # ä½¿ç”¨ endpoint_id ä½œä¸º model
                messages=messages,
                temperature=0.7,
                max_tokens=2000,
                stream=True
            )
            
            for chunk in stream_response:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    response_text += content
                    yield content
            
            # è§£ææœ€ç»ˆç»“æœ
            result = self._parse_response(response_text)
            yield result
        
        except Exception as e:
            print(f"è±†åŒ… API è°ƒç”¨å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            yield {
                'answer': f"æŠ±æ­‰ï¼ŒAI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚é”™è¯¯ä¿¡æ¯: {str(e)}",
                'show_chart': False,
                'chart_type': None,
                'chart_col': None,
                'raw_response': ''
            }
    
    def _parse_response(self, response_text):
        """è§£æ AI å“åº”"""
        try:
            # å°è¯•æå– JSON
            json_match = re.search(r'\{[\s\S]*\}', response_text)
            
            if json_match:
                json_str = json_match.group(0)
                data = json.loads(json_str)
                
                return {
                    'answer': data.get('answer', response_text),
                    'show_chart': data.get('show_chart', False),
                    'chart_type': data.get('chart_type'),
                    'chart_col': data.get('chart_col'),
                    'raw_response': response_text
                }
            else:
                # å¦‚æœæ²¡æœ‰ JSONï¼Œè¿”å›çº¯æ–‡æœ¬
                return {
                    'answer': response_text,
                    'show_chart': False,
                    'chart_type': None,
                    'chart_col': None,
                    'raw_response': response_text
                }
        
        except Exception as e:
            print(f"å“åº”è§£æå¤±è´¥: {str(e)}")
            return {
                'answer': response_text,
                'show_chart': False,
                'chart_type': None,
                'chart_col': None,
                'raw_response': response_text
            }
    
    def _mock_chat(self, query, dataframe_context=None):
        """Mock æ¨¡å¼ (ç”¨äºæµ‹è¯•)"""
        query_lower = query.lower()
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦å›¾è¡¨
        chart_keywords = ['ç”»', 'ç»˜åˆ¶', 'å›¾', 'chart', 'plot', 'å¯è§†åŒ–', 'å±•ç¤ºå›¾è¡¨', 'è¶‹åŠ¿']
        show_chart = any(kw in query_lower for kw in chart_keywords)
        
        # åˆ¤æ–­å›¾è¡¨ç±»å‹
        chart_type = None
        chart_col = None
        
        if show_chart and dataframe_context is not None:
            # é€‰æ‹©å›¾è¡¨ç±»å‹
            if 'æŸ±çŠ¶å›¾' in query_lower or 'bar' in query_lower:
                chart_type = 'bar'
            elif 'æŠ˜çº¿å›¾' in query_lower or 'line' in query_lower or 'è¶‹åŠ¿' in query_lower:
                chart_type = 'line'
            elif 'é¥¼å›¾' in query_lower or 'pie' in query_lower:
                chart_type = 'pie'
            elif 'æ•£ç‚¹å›¾' in query_lower or 'scatter' in query_lower:
                chart_type = 'scatter'
            else:
                chart_type = 'bar'  # é»˜è®¤
            
            # é€‰æ‹©æ•°æ®åˆ—
            numeric_cols = dataframe_context.select_dtypes(include=['float64', 'int64']).columns.tolist()
            
            if 'roa' in query_lower and 'ROA' in dataframe_context.columns:
                chart_col = 'ROA'
            elif 'è´Ÿå€º' in query_lower or 'debt' in query_lower:
                chart_col = 'Debt_Ratio' if 'Debt_Ratio' in dataframe_context.columns else numeric_cols[0]
            elif 'å‡€æ”¶å…¥' in query_lower:
                chart_col = 'Net_Income_Ratio' if 'Net_Income_Ratio' in dataframe_context.columns else numeric_cols[0]
            else:
                chart_col = numeric_cols[0] if numeric_cols else None
        
        # ç”Ÿæˆå›ç­”
        if show_chart:
            answer = f"å¥½çš„ï¼Œæˆ‘ä¸ºæ‚¨ç”Ÿæˆäº† {chart_col} çš„{chart_type}å›¾è¡¨ã€‚ä»æ•°æ®ä¸­å¯ä»¥çœ‹å‡ºï¼Œè¯¥æŒ‡æ ‡çš„åˆ†å¸ƒæƒ…å†µå¦‚å›¾æ‰€ç¤ºã€‚"
        else:
            # æ™®é€šå¯¹è¯
            if 'ä½ å¥½' in query_lower or 'hello' in query_lower:
                answer = "æ‚¨å¥½ï¼æˆ‘æ˜¯è±†åŒ… AI é‡‘èåˆ†æåŠ©æ‰‹ã€‚æˆ‘å¯ä»¥å¸®æ‚¨åˆ†ææ•°æ®ã€ç”Ÿæˆå›¾è¡¨ã€å›ç­”é—®é¢˜ã€‚è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨ï¼Ÿ"
            elif 'å¸®åŠ©' in query_lower or 'help' in query_lower:
                answer = """
æˆ‘å¯ä»¥å¸®æ‚¨å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

ğŸ“Š **æ•°æ®åˆ†æ**ï¼š
- "åˆ†æä¸€ä¸‹ä¼ä¸šçš„è´¢åŠ¡çŠ¶å†µ"
- "ROA æŒ‡æ ‡çš„å«ä¹‰æ˜¯ä»€ä¹ˆ"

ğŸ“ˆ **å›¾è¡¨ç”Ÿæˆ**ï¼š
- "ç”»å‡º ROA çš„æŸ±çŠ¶å›¾"
- "å±•ç¤ºè´Ÿå€ºç‡çš„è¶‹åŠ¿å›¾"

ğŸ’¬ **æ™ºèƒ½é—®ç­”**ï¼š
- å›ç­”é‡‘èç›¸å…³é—®é¢˜
- æä¾›ä¸“ä¸šå»ºè®®

è¯·ç›´æ¥è¾“å…¥æ‚¨çš„éœ€æ±‚ï¼
                """
            else:
                answer = f"æˆ‘ç†è§£æ‚¨æƒ³äº†è§£ã€Œ{query}ã€ã€‚åŸºäºå½“å‰æ•°æ®ï¼Œæˆ‘å»ºè®®æ‚¨å¯ä»¥å°è¯•æ›´å…·ä½“çš„é—®é¢˜ï¼Œæˆ–è€…è¦æ±‚æˆ‘ç”Ÿæˆç›¸å…³å›¾è¡¨æ¥è¾…åŠ©åˆ†æã€‚"
        
        return {
            'answer': answer,
            'show_chart': show_chart,
            'chart_type': chart_type,
            'chart_col': chart_col,
            'raw_response': answer
        }
    
    def generate_chart(self, data_df, chart_type, chart_col):
        """
        ç”Ÿæˆå›¾è¡¨
        
        Args:
            data_df: æ•°æ® DataFrame
            chart_type: å›¾è¡¨ç±»å‹
            chart_col: æ•°æ®åˆ—å
            
        Returns:
            plotly.graph_objects.Figure: å›¾è¡¨å¯¹è±¡
        """
        try:
            if chart_col not in data_df.columns:
                return None
            
            # é™åˆ¶æ•°æ®é‡
            plot_df = data_df.head(20)
            
            if chart_type == 'bar':
                fig = px.bar(
                    plot_df,
                    y=chart_col,
                    title=f"{chart_col} æŸ±çŠ¶å›¾",
                    labels={chart_col: chart_col}
                )
            
            elif chart_type == 'line':
                fig = px.line(
                    plot_df,
                    y=chart_col,
                    title=f"{chart_col} è¶‹åŠ¿å›¾",
                    labels={chart_col: chart_col}
                )
            
            elif chart_type == 'pie':
                # é¥¼å›¾éœ€è¦åˆ†ç»„
                value_counts = data_df[chart_col].value_counts().head(10)
                fig = px.pie(
                    values=value_counts.values,
                    names=value_counts.index,
                    title=f"{chart_col} åˆ†å¸ƒé¥¼å›¾"
                )
            
            elif chart_type == 'scatter':
                numeric_cols = data_df.select_dtypes(include=['float64', 'int64']).columns.tolist()
                if len(numeric_cols) >= 2:
                    fig = px.scatter(
                        plot_df,
                        x=numeric_cols[0],
                        y=chart_col,
                        title=f"{numeric_cols[0]} vs {chart_col} æ•£ç‚¹å›¾"
                    )
                else:
                    return None
            
            else:
                return None
            
            fig.update_layout(height=400)
            return fig
        
        except Exception as e:
            print(f"å›¾è¡¨ç”Ÿæˆå¤±è´¥: {str(e)}")
            return None
    
    def generate_analysis_report(self, risk_score, risk_type, input_features):
        """
        ç”Ÿæˆé£é™©åˆ†ææŠ¥å‘Š (ä¿ç•™åŸæœ‰åŠŸèƒ½)
        
        Args:
            risk_score: é£é™©è¯„åˆ† (0-1)
            risk_type: é£é™©ç±»å‹ ('corporate' or 'personal')
            input_features: è¾“å…¥ç‰¹å¾å­—å…¸
            
        Returns:
            str: AI ç”Ÿæˆçš„åˆ†ææŠ¥å‘Š
        """
        risk_percentage = risk_score * 100
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # æ„å»º Prompt
        if risk_type == 'corporate':
            prompt = f"""
è¯·ä½œä¸ºä¸“ä¸šçš„é‡‘èé£é™©åˆ†æå¸ˆï¼Œåˆ†æä»¥ä¸‹ä¼ä¸šçš„ç ´äº§é£é™©ï¼š

**é£é™©è¯„åˆ†**: {risk_percentage:.1f}%
**è´¢åŠ¡æŒ‡æ ‡**:
- ROA (èµ„äº§å›æŠ¥ç‡): {input_features.get('ROA', 0):.3f}
- è´Ÿå€ºæ¯”ç‡: {input_features.get('Debt_Ratio', 0):.1%}
- å‡€æ”¶å…¥æ¯”ç‡: {input_features.get('Net_Income_Ratio', 0):.3f}
- æ¯›åˆ©ç‡: {input_features.get('Gross_Margin', 0):.1%}
- æµåŠ¨è´Ÿå€ºæ¯”ç‡: {input_features.get('Liability_Assets_Ratio', 0):.1%}

è¯·æä¾›ï¼š
1. é£é™©ç­‰çº§åˆ¤å®š
2. æ ¸å¿ƒæŒ‡æ ‡åˆ†æ
3. é£é™©å› ç´ è¯†åˆ«
4. æŠ•èµ„å»ºè®®

è¦æ±‚ï¼šä¸“ä¸šã€ç®€æ´ã€å¯æ“ä½œã€‚
            """
        else:
            prompt = f"""
è¯·ä½œä¸ºä¸“ä¸šçš„ä¿¡è´·å®¡æ‰¹ä¸“å®¶ï¼Œåˆ†æä»¥ä¸‹ä¸ªäººçš„ä¿¡è´·è¿çº¦é£é™©ï¼š

**é£é™©è¯„åˆ†**: {risk_percentage:.1f}%
**ç”³è¯·äººä¿¡æ¯**:
- å¹´é¾„: {input_features.get('Age', 0)} å²
- ä¿¡è´·é‡‘é¢: {input_features.get('Credit_amount', 0):,.0f} å…ƒ
- è´·æ¬¾æœŸé™: {input_features.get('Duration', 0)} ä¸ªæœˆ

è¯·æä¾›ï¼š
1. é£é™©ç­‰çº§åˆ¤å®š
2. ç”³è¯·äººç”»åƒåˆ†æ
3. å®¡æ‰¹å»ºè®®

è¦æ±‚ï¼šä¸“ä¸šã€ç®€æ´ã€å¯æ“ä½œã€‚
            """
        
        # å¦‚æœæ˜¯çœŸå® APIï¼Œè°ƒç”¨è±†åŒ…
        if not self.use_mock:
            try:
                result = self.chat(prompt)
                return result['answer']
            except:
                pass
        
        # Mock æ¨¡å¼æˆ– API å¤±è´¥æ—¶çš„é™çº§å¤„ç†
        return self._generate_mock_report(risk_score, risk_type, input_features)
    
    def _generate_mock_report(self, risk_score, risk_type, input_features):
        """Mock æŠ¥å‘Šç”Ÿæˆ (é™çº§æ–¹æ¡ˆ)"""
        risk_percentage = risk_score * 100
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        if risk_type == 'corporate':
            roa = input_features.get('ROA', 0)
            debt_ratio = input_features.get('Debt_Ratio', 0)
            
            if risk_score > 0.7:
                return f"""
ğŸš¨ **é«˜é£é™©é¢„è­¦**

**åˆ†ææ—¶é—´**: {current_time}  
**é£é™©ç­‰çº§**: ğŸ”´ æé«˜é£é™© ({risk_percentage:.1f}%)

### æ ¸å¿ƒæŒ‡æ ‡è¯Šæ–­
- ROA: {roa:.3f} {'âš ï¸ åä½' if roa < 0.3 else 'âœ“ å°šå¯'}
- è´Ÿå€ºæ¯”ç‡: {debt_ratio:.1%} {'ğŸ”´ è¿‡é«˜' if debt_ratio > 0.5 else 'âš ï¸ åé«˜'}

### AI å»ºè®®
ğŸš« **ä¸å»ºè®®æŠ•èµ„**ï¼šç ´äº§é£é™©é«˜è¾¾ {risk_percentage:.1f}%ï¼Œå»ºè®®è§„é¿ã€‚
"""
            else:
                return f"""
âœ… **ä½é£é™©ä¼˜è´¨æ ‡çš„**

**åˆ†ææ—¶é—´**: {current_time}  
**é£é™©ç­‰çº§**: ğŸŸ¢ ä½é£é™© ({risk_percentage:.1f}%)

### æ ¸å¿ƒæŒ‡æ ‡è¯Šæ–­
- ROA: {roa:.3f} âœ¨ ä¼˜ç§€
- è´Ÿå€ºæ¯”ç‡: {debt_ratio:.1%} âœ“ åˆç†

### AI å»ºè®®
âœ… **æ¨èæŠ•èµ„**ï¼šè´¢åŠ¡ç¨³å¥ï¼Œè¿çº¦é£é™©ä»… {risk_percentage:.1f}%ã€‚
"""
        else:
            age = input_features.get('Age', 0)
            
            if risk_score > 0.7:
                return f"""
ğŸš¨ **é«˜è¿çº¦é£é™©**

**é£é™©ç­‰çº§**: ğŸ”´ é«˜é£é™© ({risk_percentage:.1f}%)

### ç”³è¯·äººç”»åƒ
- å¹´é¾„: {age} å²

### AI å»ºè®®
ğŸš« **ä¸å»ºè®®æ‰¹å‡†**ï¼šè¿çº¦æ¦‚ç‡ {risk_percentage:.1f}%ï¼Œé£é™©è¿‡é«˜ã€‚
"""
            else:
                return f"""
âœ… **ä¼˜è´¨å®¢æˆ·**

**é£é™©ç­‰çº§**: ğŸŸ¢ ä½é£é™© ({risk_percentage:.1f}%)

### ç”³è¯·äººç”»åƒ
- å¹´é¾„: {age} å²

### AI å»ºè®®
âœ… **æ¨èæ‰¹å‡†**ï¼šè¿çº¦é£é™©ä»… {risk_percentage:.1f}%ï¼Œå¯å¿«é€Ÿæ‰¹å‡†ã€‚
"""


# å‘åå…¼å®¹ï¼šä¿ç•™ FinancialLLM ç±»å
class FinancialLLM(DoubaoAgent):
    """å‘åå…¼å®¹çš„ç±»å"""
    pass
